# -*- coding: utf-8 -*-
"""논문데이터전처리.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yp4baeaSHKXu3V5wwV9CYrA4a0VyHbIt
"""

!pip install mxnet
!pip install gluonnlp pandas tqdm
!pip install sentencepiece
!pip install transformers==3.0.2
!pip install torch

!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'

!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master

#kobert
from kobert.utils import get_tokenizer
from kobert.pytorch_kobert import get_pytorch_kobert_model
from kobert_tokenizer import KoBERTTokenizer

#transformers
from transformers import AdamW
from transformers.optimization import get_cosine_schedule_with_warmup
from transformers import BertModel

import pandas as pd
df = pd.read_csv('_건축-건설-도시공학.csv', encoding='euc-kr')

data= df[['_제목','_발행연도']]
data

#import할 패키지 목록
!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash

from konlpy.tag import Okt, Mecab

okt = Okt()
mecab = Mecab()

title = df[['_제목']]

print(title[:999])

mecab.nouns('나는 준보 심준보에요.')

title['_제목']
title

tit=title['_제목'].apply(mecab.nouns)
tit

# str=' '.join(tit[2])

list = []
num = 0

for i in tit:
  str = ' '.join(tit[num])
  num = num+1
  list.append(str)

print(list)

fc_name = 'C:\\Users\\sjbss\\Desktop\\web\\rissss.csv'
df = pd.DataFrame(list)
df.to_csv(fc_name,index=False, encoding="utf-8-sig")

data['정제']=title['제목'].apply(mecab.nouns)
data

stop_words = ['연구','분석','모델','개발']

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

data['정제후불용어처리']=0
data

#stop_words = pd.read_csv('불용어처리.csv', encoding='euc-kr')
#stop_words

stopwords="연구 개발 모델"

end=pd.DataFrame({'처리':[]})
boo=pd.DataFrame({'처리':[]})
boo=data['정제']
end
boo
#end = data['정제']

boo.loc[0]

i=0
for i in boo.loc[i]:
  if i not in stopwords:
    end[i].append(boo.loc[i])

end